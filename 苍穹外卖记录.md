# 苍穹外卖记录

## Day1

### 开始

前端的页面和后端的框架都是由黑马提供，先将前端的项目放入一个没有中文字符的文件夹中，然后启动nginx，在浏览器中输入local host直接登入页面，默认端口是80，然后将后端项目拉到idea中，配置一下本地仓库和远程仓库，然后直接提交，工程中的.gitignore这个文件是用来标记不需要跟踪的项目。然后启动项目，发现出错了，问了ai说是黑马给的项目依赖版本太低了，要么升级依赖，要么降低JDK版本，于是我又从亚马逊哪里下载17版本的JDK，然后将项目结构和maven里面的JDK重新配置了一下，然后终于运行成功了，于是我直接开始打开浏览器进行联调测试，输入admin和123456后发现登录不上一直转圈，我直接打开我心爱的idea然后看控制台，发现

```java
2025-07-09 09:26:37.677 ERROR 10608 --- [eate-1914847495] com.alibaba.druid.pool.DruidDataSource   : create connection SQLException, url: jdbc:mysql://localhost:3306/sky_take_out?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&useSSL=false&allowPublicKeyRetrieval=true, errorCode 1045, state 28000
```

错误，这个一看就是数据库哪里的错误，我就在idea中测试了一下MySql，发现也能执行sql语句，我本想直接问AI这是怎么回事？但是我又突然想到没有配置密码呢，于是我就去找application文件，最终在sky-server的resources中发现了application.yml文件和application-dev.yml文件，前者我知道，后面那个确实第一次见，但是我最开始并不在意这个文件，直接打开了application.yml文件，找到了数据库连接那里的配置发现：

```yaml
  datasource:
    druid:
      driver-class-name: ${sky.datasource.driver-class-name}
      url: jdbc:mysql://${sky.datasource.host}:${sky.datasource.port}/${sky.datasource.database}?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&useSSL=false&allowPublicKeyRetrieval=true
      username: ${sky.datasource.username}
      password: ${sky.datasource.password}
```

这个直接就给我干傻了，于是我直接去问ai

**`${}` 语法**：

- 这是 Spring Boot 的 **属性占位符**，表示这些值不是直接写死的
- 实际值会从其他配置源获取（如 `application.yml`、环境变量等）

那我就直接去找sky，发现了：

```yaml
sky:
  jwt:
    # 设置jwt签名加密时使用的秘钥
    admin-secret-key: itcast
    # 设置jwt过期时间
    admin-ttl: 7200000
    # 设置前端传递过来的令牌名称
    admin-token-name: token
```

里面只有jwt的内容，而没有datasource，但是我看AI提到了application-dev.yml,于是我就把完整的application.yml发给了AI,于是就找到了下面这段：

```yaml
spring:
  profiles:
    active: dev  # 激活 dev 环境配置
```

Spring Boot 会额外加载：

1. `application-dev.yml`（优先级高于主配置）
2. `application-dev.properties`

实际查找顺序：

1. 命令行参数
2. 环境变量（如 `SKY_DATASOURCE_HOST`）
3. `application-dev.yml`
4. `application-dev.properties`
5. `application.yml`（当前文件）
6. `application.properties`

于是我恍然大悟，直接去application-dev中找，果然发现了：

```yaml
sky:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    host: localhost
    port: 3306
    database: sky_take_out
    username: root
    password: root
```

然后我直接将pwd改为我自己的，重新启动服务，直接在浏览器中点击确定，直接登进去了。

接下来是引出一个问题：为什么我们访问的路径和后端给的不一样但是却能访问到正确的内容呢?

### Nginx反向代理和负载均衡

#### 第一部分：反向代理

要理解反向代理，我们先要明白什么是“正向代理”。

- **正向代理 (Forward Proxy)**:
  - **为谁服务**：为**客户端**服务。
  - **工作方式**：它位于客户端和目标服务器之间。客户端（比如你的浏览器）知道自己想访问的目标服务器（比如 google.com），但它不直接访问，而是把请求发给代理服务器，由代理服务器代为访问，然后把结果返回给客户端。
  - **典型例子**：公司内部的上网代理、科学上网工具。客户端清楚地知道目标是谁，但需要一个“中间人”来帮忙访问。
  - **隐藏了谁**：隐藏了真实的**客户端**。目标服务器只知道是代理服务器在访问它，不知道背后真正的用户是谁。
- **反向代理 (Reverse Proxy)**:
  - **为谁服务**：为**服务器端**服务。
  - **工作方式**：它也位于客户端和服务器之间。但这次，客户端（浏览器）以为自己直接访问的就是目标服务器。它向反向代理服务器（比如 www.example.com）发送请求，反向代理服务器在内部将这个请求转发给一个或多个真正的业务服务器（应用服务器）去处理，然后将处理结果返回给客户端。
  - **典型例子**：几乎所有的大型网站都在使用。你访问 www.taobao.com，背后可能有成千上万台服务器在为你服务，但你只和那个叫 www.taobao.com 的反向代理打交道。
  - **隐藏了谁**：隐藏了真实的**后端服务器**。客户端完全不知道后端服务器的IP地址、数量和架构。

 Nginx 为什么要做反向代理？（它的好处）

1. **安全与隔离 (Security)**:
   - 后端应用服务器不直接暴露在公网上，所有流量都必须经过 Nginx。这使得 Nginx 成为一道安全屏障，可以配置防火墙规则、抵御DDoS等网络攻击。
2. **负载均衡 (Load Balancing)**:
   - 这是最重要的用途之一。如果后端有一组服务器，Nginx 可以把请求分发给它们，避免单台服务器压力过大。我们稍后详谈。
3. **SSL/TLS 卸载 (SSL Termination)**:
   - HTTPS 的加解密过程非常消耗 CPU 资源。可以让 Nginx 专门负责与客户端进行 HTTPS 通信，然后 Nginx 与后端服务器之间使用普通的 HTTP 通信。这样，后端应用服务器就可以专注于业务逻辑，而不用消耗资源在加解密上。
4. **动静分离与缓存 (Caching & Serving Static Files)**:
   - Nginx 处理静态文件（如图片、CSS、JavaScript）的速度非常快。可以让 Nginx 直接处理静态文件请求，而只将动态请求（如需要查询数据库的API）转发给后端的应用服务器（如 Tomcat, Node.js）。
   - Nginx 还可以缓存后端服务器的响应内容，对于不常变化的请求，直接返回缓存，极大减轻后端压力。
5. **统一入口和路径重写 (Centralized Entry Point & URL Rewriting)**:
   - 无论后端有多少个微服务或应用，都可以通过 Nginx 这一个域名入口，根据不同的URL路径（location）转发到不同的服务上。

一个最简单的反向代理配置如下：

```nginx
# http 块是 Nginx 配置的主体
http {
    # server 块定义了一个虚拟主机
    server {
        # 监听 80 端口
        listen 80;
        # 客户端访问的域名
        server_name www.mydomain.com;

        # location 块匹配 URL 路径
        # / 表示匹配所有请求
        location / {
            # 这就是核心！将请求转发到指定的后端服务器
            # proxy_pass 指令告诉 Nginx 把请求代理到哪里
            proxy_pass http://192.168.1.10:8080;

            # （可选）设置一些代理相关的 HTTP 头部
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}
```

#### 第二部分：负载均衡

1. 什么是负载均衡？

想象一下，一个网站的访问量非常大，一台服务器根本处理不过来。怎么办？很简单，增加服务器！

现在你有 3 台一模一样的服务器来处理相同的业务。

负载均衡的作用就是**将海量的客户端请求，通过某种算法，“公平”地分配给这 3 台服务器**，确保没有哪一台服务器被累死，而其他服务器在“摸鱼”。

所以，负载均衡是反向代理的一种具体应用场景：**当 proxy_pass 后面不是一台服务器，而是一组服务器时，就实现了负载均衡。**

Nginx 如何实现负载均衡？

Nginx 通过 upstream 模块来实现负载均衡。upstream 定义了一个后端服务器的集群。

Nginx 负载均衡配置示例

```nginx
http {
    # 1. 定义一个上游服务器集群，并取个名字叫 "backend_servers"
    upstream backend_servers {
        # 这里列出所有提供服务的后端服务器
        # 默认使用轮询（Round Robin）策略
        server 192.168.1.10:8080;
        server 192.168.1.11:8080;
        server 192.168.1.12:8080;
    }

    server {
        listen 80;
        server_name www.mydomain.com;

        location / {
            # 2. 将请求转发到上面定义的服务器集群
            proxy_pass http://backend_servers;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}
解释:
我们用 upstream backend_servers 定义了一个服务器池，里面包含了 3 台服务器。
在 location 块中，proxy_pass 指向的不再是具体的 IP 地址，而是 upstream 的名字 http://backend_servers。
当请求进来时，Nginx 会根据负载均衡策略，从这 3 台服务器中选择一台来转发请求。
```

#####  Nginx 的负载均衡策略

Nginx 提供了多种分发策略，可以根据业务需求选择：

1. **轮询 (Round Robin) - 默认**

   - **描述**：按顺序将请求逐一分配给后端服务器，周而复始。
   - **优点**：简单、公平。
   - **缺点**：如果服务器性能不同，性能好的服务器可能和性能差的服务器承担相同的压力。
   - **配置**：upstream 块里直接写 server 即可，无需额外指令。

2. **加权轮询 (Weighted Round Robin)**

   - **描述**：在轮询的基础上，为每台服务器指定一个权重（weight）。权重越高的服务器，被分配到的请求比例就越高。

   - **场景**：适用于后端服务器性能不一的情况。

   - **配置**：

     ```nginx
     upstream backend_servers {
         server 192.168.1.10:8080 weight=3; # 这台服务器处理 3/5 的请求
         server 192.168.1.11:8080 weight=1; # 这台处理 1/5
         server 192.168.1.12:8080 weight=1; # 这台处理 1/5
     }
     ```

3. **IP 哈希 (IP Hash)**

   - **描述**：根据客户端的 IP 地址进行哈希计算，将结果与服务器数量取模，确保来自**同一个客户端**的请求，总是被转发到**同一台**后端服务器。

   - **场景**：需要**会话保持 (Session Persistence)** 的场景。比如，用户登录信息保存在某台服务器的 Session 中，如果把他的下一个请求转发到另一台服务器，登录状态就丢失了。

   - **配置**：

     ```nginx
     upstream backend_servers {
         ip_hash; # 加上这条指令
         server 192.168.1.10:8080;
         server 192.168.1.11:8080;
         server 192.168.1.12:8080;
     }
     ```

4. **最少连接 (Least Connections)**

   - **描述**：将请求转发给当前**活动连接数最少**的服务器。

   - **场景**：当请求处理时间长短不一，导致各服务器负载动态变化时，这种策略比轮询更智能、更均衡。

   - **配置**：

     ```nginx
     upstream backend_servers {
         least_conn; # 加上这条指令
         server 192.168.1.10:8080;
         server 192.168.1.11:8080;
         server 192.168.1.12:8080;
     }
     ```

5. 健康检查 (Health Check)

负载均衡还有一个重要功能：**自动剔除故障服务器**。如果 upstream 中的某台服务器宕机了，Nginx 会自动检测到，并停止向它转发请求，等它恢复后再重新加入服务。这就保证了服务的高可用性。

可以在 server 指令后添加 max_fails 和 fail_timeout 参数来配置：

```
upstream backend_servers {
    server 192.168.1.10:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.11:8080;
}
```

- max_fails=3：表示在 fail_timeout 时间内，如果连接失败了 3 次。
- fail_timeout=30s：则认为这台服务器宕机了，并在接下来的 30 秒内不再向它转发请求。

对于所给的配置：

```nginx
upstream webservers{
    server 192.168.100.128:8080;
    server 192.168.100.129:8080;
}
server{
    listen 80;
    server_name localhost;

    location /api/ {
        proxy_pass http://webservers/admin/; #负载均衡
    }
}
upstream 是 Nginx 用于定义“上游服务器”集群的指令。
webservers 是你为这个服务器集群取的名字，可以任意命名。
这个集群里包含了两台后端业务服务器：
192.168.100.128:8080
192.168.100.129:8080
因为没有指定负载均衡策略（比如 ip_hash 或 least_conn），Nginx 会默认使用轮询 (Round Robin) 策略。也就是说，第一个请求给第一台服务器，第二个请求给第二台，第三个再给第一台，如此循环往复。
listen 80;: Nginx 监听本机的 80 端口，接收外部的 HTTP 请求。
server_name localhost;: 当请求的域名是 localhost 时，这个 server 块会生效。
location /api/ { ... }: 这是最核心的路由规则。它会匹配所有以 /api/ 开头的请求。例如 http://localhost/api/users 或者 http://localhost/api/products/123 都会被这个 location 块捕获。
proxy_pass http://webservers/admin/;: 这就是反向代理兼负载均衡的实现。
proxy_pass 指令告诉 Nginx：“把捕获到的请求转发出去”。
转发到哪里呢？http://webservers，这个 webservers 正是我们在上面 upstream 中定义好的服务器集群的名字。
Nginx 会根据负载均衡策略（这里是轮询）从 192.168.100.128:8080 和 192.168.100.129:8080 中选择一台，然后把请求发过去。

一个重要的细节：URL路径重写
请注意 proxy_pass 后面还跟着 /admin/。这会导致 Nginx 在转发时重写 URL。规则是：将 location 匹配的路径替换为 proxy_pass 后的路径。
让我们来看一个具体的例子：
客户端（你的浏览器）发起一个请求：http://localhost/api/get_user_info
Nginx 收到请求，监听到 80 端口，且域名是 localhost。
Nginx 发现请求路径 /api/get_user_info 匹配了 location /api/。		
Nginx 准备执行 proxy_pass。
它从 webservers 集群中通过轮询选择一台服务器，比如 192.168.100.128:8080。
Nginx 会将原始请求中的 /api/ 部分替换为 /admin/。
最终，Nginx 实际发往后端服务器的请求是：http://192.168.100.128:8080/admin/get_user_info。
```

#### 密码加密

对于数据库中的密码，我们不能使用明文，要进行加密，这里使用MD5加密方式，这是一种不可逆的加密，因此我们在将密码写入数据库中时，就可以将加密后的密码写入，在对比时，在java中将用户输入的密码加密后在和数据库中的进行比对。

```java
DigestUtils.md5DigestAsHex(password.getBytes());直接使用工具类就行，返回String类型的文件
```

#### Swagger

一种技术可以生成接口文档

#####  我们为什么需要 Swagger？

在没有 Swagger 的时代，API 开发充满了混乱和低效：

1. **沟通成本高**：前端工程师需要不断地去问后端工程师：“那个获取用户列表的接口是啥？要传什么参数？返回的数据长什么样？”
2. **文档维护难**：后端工程师通常用 Word 或 Wiki 来手写 API 文档。但代码一旦修改，文档就很容易忘记更新，导致文档与实际代码不一致，坑害了使用者。
3. **测试效率低**：前端或测试人员需要使用 Postman、curl 等工具，手动填写 URL、参数、请求头来测试接口，非常繁琐。
4. **协作效率差**：前后端分离开发时，前端常常需要等后端把接口开发完才能开始联调。如果接口定义不清晰，联调过程会充满争吵和返工。

**Swagger 的出现，完美地解决了以上所有问题：**

- **文档即代码 (Documentation as Code)**：API 文档不再是独立的文件，而是可以直接从代码（通过注解）自动生成。代码一变，文档自动更新，保证了**文档的实时性和准确性**。
- **清晰的“契约”**：生成的 Swagger 文档成为了前后端开发人员之间的一份“技术契约”。双方都按照这份契约来开发，减少了沟通障碍和扯皮。
- **交互式调试**：Swagger UI 提供了一个 "Try it out" 功能，你可以在文档页面上直接填写参数、发起 API 请求，并立即看到真实的响应结果。这极大地简化了接口的测试和调试过程。
- **加速开发**：
  - **并行开发**：一旦 API 契约（规范文件）定下来，前后端就可以同时开工。前端甚至可以用 Swagger Codegen 生成的模拟客户端来开发，而无需等待后端接口完成。
  - **代码自动生成**：Swagger Codegen 能自动生成大量重复的模板代码（如网络请求、数据模型），让开发者可以更专注于业务逻辑。



Knife4j 是一个专注于**提升 API 文档体验**的工具。它通过与 Springfox/Springdoc 等标准库协同工作，利用你写的注解信息，为开发者提供了一个功能远超原生 Swagger UI 的文档平台，极大地提高了 API 的可读性和调试效率。

##### 常用的注解：

###### 1. @Api

- **作用**: 用来标记一个 Controller 类，把它定义为一个 API 资源。它提供了对整个 Controller 的分组命名和描述。

- **使用位置**: **类**上，通常是 Controller 类。

- **常用属性**:

  - tags: **（最常用）** 字符串数组，用于给这个 Controller 下的所有接口进行分组。在 Knife4j 左侧的菜单中，tags 的第一个值通常会成为分组的标题。这是实现接口分类的关键。
  - value: tags 属性的别名。如果只提供一个分组名，用 value = "用户管理" 和 tags = "用户管理" 效果一样。推荐统一使用 tags。
  - description: 对这个 API 资源的描述，在 Knife4j 界面上通常不太明显，tags 更为重要。

  

------



###### 2. @ApiOperation

- **作用**: 对 Controller 中的一个具体方法（一个 API 接口）进行详细的描述。
- **使用位置**: **方法**上。
- **常用属性**:
  - value: **（最常用）** 对接口用途的**简短概括**。它会显示在接口列表的标题位置，必须清晰明了。例如：“根据ID查询用户信息”。
  - notes: 对接口的**详细描述**。可以写得更长，支持换行，用于解释接口的业务逻辑、前置条件、注意事项等。

------



###### 3. @ApiModel

- **作用**: 用于描述一个作为数据模型的 Java Bean 类，比如 DTO (Data Transfer Object)、VO (View Object) 或者 Entity。
- **使用位置**: **类**上，通常是实体类、DTO、VO 等。
- **常用属性**:
  - value: 给这个模型起一个在 API 文档中显示的名字。如果不写，默认使用类名。
  - description: 对这个模型的详细描述，说明它的用途。

------



###### 4. @ApiModelProperty

- **作用**: 用于描述模型类中的某一个属性（字段），这是生成文档时最关键、最详细的注解之一。
- **使用位置**: **类的属性（字段）**上。
- **常用属性**:
  - value: **（最常用）** 对字段含义的描述。例如：“用户姓名”。
  - name: 重命名字段在文档中的显示。一般不用，默认使用字段名。
  - required: **（非常重要）**布尔值，true 或 false，指明这个字段在请求时是否为必填项。Knife4j 会对必填项进行特殊标记（如红色星号）。
  - example: **（非常实用）**提供一个示例值。这在调试时非常方便，Knife4j 会自动将示例值填充到调试界面的输入框中。
  - hidden: 布尔值，如果为 true，该字段将不会在 API 文档中显示。适用于一些你不想暴露给前端的内部字段。
  - allowableValues: 限制字段的取值范围。例如 allowableValues = "range[1, 100]" 表示1到100之间，allowableValues = "man,woman" 表示只能是'man'或'woman'。

------

### Maven中的继承和聚合

#### 继承

##### 为什么需要继承？

在一个大型项目中，通常会有很多模块，它们可能会依赖相同的库（比如 Spring Boot, MySQL Connector）。

- **没有继承的痛点**：每个模块的 pom.xml 都需要独立声明这些依赖和它们的版本。如果某天需要升级 Spring Boot 的版本，你必须手动去修改**所有**模块的 pom.xml，这非常繁琐且容易出错。
- **继承的优势**：只需在父 POM 中定义一次版本号，所有子模块继承即可。升级时，只需修改父 POM 一处地方，所有子模块的版本都会自动更新。这保证了**版本统一**和**维护便捷**。****

##### 如何实现继承？

在子文件中添加标签如下：

```xml
    <parent>
        <artifactId>sky-take-out</artifactId>
        <groupId>com.sky</groupId>
        <version>1.0-SNAPSHOT</version>
    </parent>
```

这样子类文件就会继承父类中的所有依赖，那如果各个子类中存在不同的依赖该怎么办呢？能否将所需要的依赖全都写入父类pom文件中呢？这样理论上可以，但是非常不推荐，因为这样会浪费资源。那要怎么办呢？

```xml
<dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.mybatis.spring.boot</groupId>
                <artifactId>mybatis-spring-boot-starter</artifactId>
                <version>${mybatis.spring}</version>
            </dependency>
        </dependencies>
</dependencyManagement>
```

写在这个标签中的依赖如果在子类中被使用了，那么就会按照这里面的版本号统一管理，如何快速更改版本号，要使用到另外一个标签叫做`<properties>`

```xml
<properties>
	<!-- 使用 properties 统一管理版本号，这是最佳实践 -->
	<spring.version>5.3.23</spring.version>
	<junit.version>5.8.2</junit.version>
</properties>

<!-- 2. 在这里集中管理所有依赖的版本 -->
<dependencyManagement>
	<dependencies>
		<!-- 声明 Spring Framework 的版本 -->
		<dependency>
			<groupId>org.springframework</groupId>
			<artifactId>spring-core</artifactId>
			<version>${spring.version}</version>
		</dependency>
		<dependency>
			<groupId>org.springframework</groupId>
			<artifactId>spring-context</artifactId>
			<version>${spring.version}</version>
		</dependency>

		<!-- 声明 JUnit 5 的版本 -->
		<dependency>
			<groupId>org.junit.jupiter</groupId>
			<artifactId>junit-jupiter-api</artifactId>
			<version>${junit.version}</version>
			<scope>test</scope> <!-- 这里也可以管理 scope -->
		</dependency>
	</dependencies>
</dependencyManagement>
```

#### 聚合

如果说**继承**是解决“**如何配置**”子模块（How to configure），那么**聚合**就是解决“**如何构建**”这些子模块（How to build）。

**聚合**允许你从一个顶层项目（称为聚合器或根项目）出发，用**一条命令**来构建它所管理的所有子模块。

##### 如何实现聚合？

实现聚合非常简单，只需要在你的顶层（父）POM 文件中做一件事：**添加 <modules> 标签**。

```xml
<!-- 2. 这是聚合的核心：<modules> 标签 -->
<modules>
    <!-- 每个 <module> 指向一个子模块的目录名 -->
    <module>module-a</module>
    <module>module-b</module>
</modules>
```

##### 聚合是如何工作的？

1. 读取根目录的 pom.xml。
2. 发现这是一个聚合项目（因为它有 <modules> 标签）。
3. 它会创建一个**反应堆（Reactor）**。Reactor 是 Maven 用来管理和排序多模块构建顺序的内部机制。
4. Maven 会分析所有模块之间的依赖关系。例如，如果 module-b 依赖于 module-a，Maven 会自动识别出来。
5. Reactor 会制定一个**正确的构建顺序**。在这个例子中，它会先构建 module-a，然后再构建 module-b，以确保 module-b 在构建时可以找到 module-a 的产物（比如 module-a.jar）。
6. 最后，它会按照这个顺序，依次在每个子模块上执行你指定的命令（clean install）。

和我想的一样，按照拓扑排序来的。

## Day2

今天要完成的任务是：

新增员工

员工分页查询

启用禁用员工账号

编辑员工

导入分类模块功能代码

### 新增员工

#### DTO？

##### 1. DTO 是什么？

**DTO** 的全称是 **Data Transfer Object**，即**数据传输对象**。

顾名思义，它的唯一目的就是**在不同层之间（尤其是在网络的两端，如前端和后端之间）充当数据的搬运工**。

把它想象成一个**“定制的包裹”**：

- 当客户（前端）要给你（后端）寄东西时，他们不会把自己的整个家当（数据库实体）都寄过来，而是会按照你提供的**“订单表格”（DTO）**，把需要的东西（如username, password）打包好，装进这个包裹里寄给你。
- 这个包裹本身很简单，只包含货物（数据）和货物的清单（属性），没有任何复杂的功能（业务逻辑）。

**DTO 的本质**：它是一个纯粹的 Java 对象（POJO - Plain Old Java Object），只包含私有属性和对应的 getter/setter 方法，不应包含任何业务逻辑。

##### 2.为什么要使用DTO？

我数据库里不是已经有 User 这个实体类（Entity/PO）了吗？为什么不直接用它来接收前端参数？还要多此一举搞个 UserDTO？

答案是，**直接使用数据库实体类（Entity）会带来巨大的风险和麻烦**。

**问题一：安全问题 - 避免数据过度暴露**

**问题二：数据结构不匹配**

**问题三：明确的校验规则**

**问题四：解耦 - 隔离变化**

#### DTO->实体类？

在开发过程中，我在Controller层使用DTO接收到了前端传来的参数，但是在Service却并没有将这个DTO对象传入Mapper层，而是将其转化为和数据库表对应的实体类后再传入如Mapper层？这是为什么？

###### 角色和职责的根本不同

**1. DTO (EmployeeAddDTO) 的职责：作为“客户订单”**

- **为“外部”服务**：它的设计完全是为了方便与外界（前端）的交互。它只包含前端需要填写、也只应该填写的信息，比如 name, email, departmentName。
- **面向特定场景**：这份“订单”是专门为“新增员工”这个场景定制的。它可能包含一些临时字段，比如 confirmPassword（确认密码），这个字段在数据库里根本不需要存储。
- **携带原始数据**：它携带的是客户填写的原始、未加工、未验证业务逻辑的数据。比如，密码是明文的。
- **生命周期短暂**：这份“订单”在 Controller 接收到，并传递给 Service 后，它的使命就基本完成了。

**2. Entity (User / Employee) 的职责：作为“车间里的产品”**

- **为“内部”服务**：它的设计严格映射数据库表的结构，是系统内部数据持久化的根本。它是我们系统内部的“事实标准”。
- **包含完整且真实的数据**：它包含了一个“产品”的所有属性，包括那些客户不应该接触的内部零件。比如：
  - id：数据库自动生成的主键。
  - password：**加密后**的密码。
  - salt：密码盐值。
  - status：员工的初始状态（如 ACTIVE），这是系统业务规则决定的，而不是客户指定的。
  - createTime / updateTime：由系统自动记录的时间戳。
- **数据是安全和完整的**：在它被存入数据库之前，必须是经过加工、处理、符合所有业务规则的“合格产品”。
- **生命周期长**：它由持久化框架（如 JPA/Hibernate）管理，代表了数据库中的一条真实记录。

### 如何获得当前正在操作者的信息？

我们通过 ThreadLocal 的 set 方法来详细解析这个过程。

首先要明白这三者的关系：Thread 和 ThreadLocal 是两个独立的顶级类。ThreadLocalMap 是 ThreadLocal 类的一个**静态内部类**，它的本质是一个**为 ThreadLocal 定制的、类似于 HashMap 的数据结构**。

**核心关系是：每个 Thread 对象内部都有一个 ThreadLocal.ThreadLocalMap 类型的成员变量，名为 threadLocals。这个 threadLocals 才是真正存储数据的地方。**	

对于set方法：

```java
public void set(T value) {
    // 1. 获取当前执行代码的线程对象
    Thread t = Thread.currentThread();

    // 2. 尝试获取该线程内部的 ThreadLocalMap
    ThreadLocalMap map = getMap(t);

    // 3. 根据 Map 是否存在，执行不同逻辑
    if (map != null) {
        // 3a. 如果 Map 已存在，直接存入数据
        map.set(this, value);
    } else {
        // 3b. 如果 Map 不存在，则为该线程创建 Map 并存入初始数据
        createMap(t, value);
    }
}
```

过程详解：

1. **获取当前线程**：通过 Thread.currentThread() 方法拿到了当前正在运行的线程，获得了一个 Thread 对象 t。
2. **获取线程的“私有仓库”**：在 ThreadLocal 类中，有一个 getMap(Thread t) 方法，它的作用就是返回 t.threadLocals，即**获取 Thread 对象内部持有的那个 threadLocals 成员变量**。这个 threadLocals 的类型正是 ThreadLocalMap，并且在线程被创建时，**它的默认值是 null**。
3. **分支处理**：
   - **如果 map 不为 null (非首次调用)**：
     这说明当前线程之前已经使用过**某个** ThreadLocal，它的 threadLocals Map 已经被创建了。这时会执行 map.set(this, value)。
     - **this**: **这里的 this 是关键，它指的是调用 set 方法的那个 ThreadLocal 实例本身。它将作为 Key。**
     - **value**: 这是我们要存入的业务数据。它将作为 Value。
     - **这一步的本质是：在当前线程的 ThreadLocalMap 中，添加或更新一个键值对，其中 Key 是 ThreadLocal 对象，Value 是我们存的数据。**
   - **如果 map 为 null (首次调用)**：
     这说明当前线程是第一次使用 ThreadLocal。这时会调用 createMap(t, value)。
     - createMap 方法会 new 一个全新的 ThreadLocalMap 对象。
     - 在创建这个新 Map 的同时，它会把**第一个键值对**（Key为 this，Value为 value）直接存进去。
     - 最后，也是最重要的一步，它会将这个新创建的 Map **赋值给当前线程的 threadLocals 成员变量** (t.threadLocals = newMap)。从此，这个线程就有了自己的“私有仓库”。

### 一请求一线程

知道了上面的内容，我们就可以联想到，将我们需要的信息保存在ThreadLocalMap()的value中，这样就可以在service层中调用线程相关的方法拿出来，那么这是一个怎样的过程呢？

1. **用户登录 (第一次请求)**
   - 你用浏览器登录账号。
   - 浏览器发送一个 POST /login 的HTTP请求到服务器。
   - Tomcat服务器从它的**线程池**中取出一个**空闲的线程**，我们叫它**线程A**。
   - **线程A** 负责处理这**整个**登录请求：执行你的 login 方法，生成JWT，然后把响应返回给浏览器。
   - 请求处理完毕，**线程A被归还到线程池中**，等待处理下一个请求（这个下一个请求可能来自任何用户）。线程A本身并不知道也**不关心**你是否登录了。
2. **用户进行操作 (第二次请求)**
   - 你在网页上点击“查询我的订单”按钮。
   - 浏览器发送一个 GET /orders 的HTTP请求，并在请求头中带上登录时获得的JWT。
   - Tomcat再次从线程池中取出一个**空闲的线程**，这次可能是**线程B**（也可能是线程A，或者任何其他空闲线程）。
   - **线程B** 开始处理这个查询订单的请求。
   - **关键点来了**：你的 JwtTokenInterceptor 在**线程B**上执行。它从请求头解析JWT，拿到了你的用户ID。然后，它调用 BaseContext.setCurrentId(你的ID)，把你的ID存入了**线程B的 ThreadLocal 空间**里。
   - **线程B** 继续执行Controller -> Service。在Service层，当需要记录操作人时，它调用 BaseContext.getCurrentId()，从**线程B的 ThreadLocal 空间**中取出了你的ID。
   - 请求处理完毕，响应返回。在afterCompletion方法中，BaseContext.removeCurrentId()被调用，**清空了线程B的 ThreadLocal 空间**。
   - **线程B被归还到线程池中**，变回一个“干净”的线程。
3. **用户进行另一次操作 (第三次请求)**
   - 你点击“修改个人信息”。
   - 浏览器发送一个 PUT /user/profile 的HTTP请求，同样带着JWT。
   - Tomcat从线程池中又取出一个空闲线程，这次可能是**线程C**。
   - **完全相同的过程在线程C上重复一遍**：拦截器在**线程C**上设置ThreadLocal，业务逻辑在**线程C**上获取ThreadLocal，最后在**线程C**上清理ThreadLocal。

总结：一个线程会完整的执行完整个请求的生命周期，这期间不会被其他线程接管，因此这就是我们获得当前操作者的信息的最佳答案！

在具体的实现类中，我们还将其分装成了一个类，明明就

### Java Web 项目中的时间格式化

#### 核心问题

在 Web 开发中，后端从数据库（如 MySQL 的 `DATETIME` 或 `TIMESTAMP` 类型）中获取到的时间数据，在 Java 中通常会映射为 `java.util.Date` 或 `java.time.LocalDateTime` 等对象。

当我们将包含这些时间对象的实体类（Entity/DTO）通过 API 返回给前端时，默认的序列化结果可能并不是我们想要的格式（例如，可能会是一个长整型的时间戳或 ISO 8601 格式的字符串 `2023-10-27T14:30:00.123`）。

**目标**：我们需要将这些时间对象，优雅地转换为前端需要的、可读性强的字符串格式，如 `yyyy-MM-dd HH:mm:ss`。

> **💡 最佳实践**
> 强烈推荐使用 Java 8 引入的 `java.time` 包下的类（如 `LocalDateTime`, `LocalDate`, `LocalTime`）来处理时间，而不是老旧的 `java.util.Date`。它们是线程安全的、API 设计更友好，并且功能更强大。

下面介绍几种在 Spring Boot/Spring MVC 项目中常用的处理方式。

---

#### 方式一：使用 `@JsonFormat` 注解（局部格式化）

这是一种最简单、最直接的方式，通过在实体类的日期字段上添加 Jackson 库的注解来指定格式。

**适用场景**：只针对个别字段或特定 DTO 进行格式化，不同地方需要不同格式。

##### 1. 如何使用

直接在你的 DTO (Data Transfer Object) 或 Entity 类的日期时间字段上添加 `@JsonFormat` 注解。

```java
import com.fasterxml.jackson.annotation.JsonFormat;
import java.time.LocalDateTime;

public class OrderDTO {

    private Long orderId;
    private String productNmae;

    // 使用 @JsonFormat 注解指定输出格式
    // timezone="GMT+8" 用于指定时区，避免因服务器时区不同导致的时间差问题
    @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss", timezone = "GMT+8")
    private LocalDateTime createTime;

    private LocalDateTime updateTime; // 未加注解，将使用全局配置或默认格式

    // Getter and Setter ...
}
```

#### 全局格式化

下面介绍在 Spring Boot/Spring MVC 项目中，实现**全局时间格式化**的两种主要方式。

---

#### 全局格式化方案对比

| 特性                  | **方式一：定制 `ObjectMapper` (推荐)**      | **方式二：替换 `HttpMessageConverter` (经典)** |
| :-------------------- | :------------------------------------------ | :--------------------------------------------- |
| **核心思想**          | 在 Spring Boot 自动配置的基础上进行**定制** | **替换** Spring Boot 默认的 JSON 消息转换器    |
| **编程风格**          | 现代 Spring Boot 风格，与自动配置协同工作   | 经典 Spring MVC 风格，拥有完全的控制权         |
| **代码简洁度**        | 更高，逻辑更内聚                            | 相对分散，需要配置类和实体类                   |
| **与 `yml` 配置关系** | **兼容**，`yml` 配置依然可作为默认值        | **不兼容**，`yml` 的 jackson 配置会失效        |

---

方式一：通过 `Jackson2ObjectMapperBuilderCustomizer` 定制 (推荐)

这种方式利用了 Spring Boot 的自动配置机制，通过一个 `Customizer` Bean 来对默认的 `ObjectMapper` 进行微调。这是目前最推荐的做法。

1. 实现步骤

创建一个配置类，并向 Spring 容器中注册一个 `Jackson2ObjectMapperBuilderCustomizer` 类型的 `@Bean`。

```java
import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalTimeDeserializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateSerializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalTimeSerializer;
import org.springframework.boot.autoconfigure.jackson.Jackson2ObjectMapperBuilderCustomizer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.time.LocalDate;
import java.time.LocalDateTime;
import java.time.LocalTime;
import java.time.format.DateTimeFormatter;

@Configuration
public class JacksonCustomizerConfig {

    private static final String DATE_FORMAT = "yyyy-MM-dd";
    private static final String DATETIME_FORMAT = "yyyy-MM-dd HH:mm:ss";
    private static final String TIME_FORMAT = "HH:mm:ss";

    @Bean
    public Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer() {
        return builder -> {
            // 格式化 LocalDateTime
            builder.serializerByType(LocalDateTime.class, 
                new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DATETIME_FORMAT)));
            builder.deserializerByType(LocalDateTime.class, 
                new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DATETIME_FORMAT)));

            // 格式化 LocalDate
            builder.serializerByType(LocalDate.class, 
                new LocalDateSerializer(DateTimeFormatter.ofPattern(DATE_FORMAT)));
            builder.deserializerByType(LocalDate.class, 
                new LocalDateDeserializer(DateTimeFormatter.ofPattern(DATE_FORMAT)));

            // 格式化 LocalTime
            builder.serializerByType(LocalTime.class, 
                new LocalTimeSerializer(DateTimeFormatter.ofPattern(TIME_FORMAT)));
            builder.deserializerByType(LocalTime.class, 
                new LocalTimeDeserializer(DateTimeFormatter.ofPattern(TIME_FORMAT)));
        };
    }
}
```

---

方式二：重写 `extendMessageConverters` 替换转换器 (经典)

这种方式通过继承 `WebMvcConfigurationSupport` 或实现 `WebMvcConfigurer`，手动创建一个新的消息转换器并替换掉默认的。这在非 Spring Boot 或老旧项目中非常常见。

1. 实现步骤

**第一步：创建一个自定义的 `ObjectMapper` 类**

这个类继承自 `ObjectMapper`，并在构造函数中定义好所有的序列化和反序列化规则。

```java
import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.module.SimpleModule;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalTimeDeserializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateSerializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalTimeSerializer;

import java.time.LocalDate;
import java.time.LocalDateTime;
import java.time.LocalTime;
import java.time.format.DateTimeFormatter;

public class CustomJacksonObjectMapper extends ObjectMapper {

    public static final String DATE_FORMAT = "yyyy-MM-dd";
    public static final String DATETIME_FORMAT = "yyyy-MM-dd HH:mm:ss";
    public static final String TIME_FORMAT = "HH:mm:ss";

    public CustomJacksonObjectMapper() {
        super();
        
        // 收到未知属性时不报异常
        this.configure(FAIL_ON_UNKNOWN_PROPERTIES, false);
        
        // 创建模块，统一注册所有的时间序列化/反序列化规则
        SimpleModule simpleModule = new SimpleModule()
                .addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DATETIME_FORMAT)))
                .addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DATE_FORMAT)))
                .addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(TIME_FORMAT)))
                
                .addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DATETIME_FORMAT)))
                .addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DATE_FORMAT)))
                .addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(TIME_FORMAT)));

        // 注册模块
        this.registerModule(simpleModule);
    }
}
```

第二步：创建一个 Web 配置类，将自定义转换器注册进去

重写 `extendMessageConverters` 方法，将使用我们自定义 `ObjectMapper` 的转换器加到列表的最前面。

示例代码（Java）

```java
import lombok.extern.slf4j.Slf4j;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.converter.HttpMessageConverter;
import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport;

import java.util.List;

@Configuration
@Slf4j
public class WebMvcConfig extends WebMvcConfigurationSupport {

    /**
     * 扩展Spring MVC的消息转换器
     * @param converters
     */
    @Override
    protected void extendMessageConverters(List<HttpMessageConverter<?>> converters) {
        log.info("扩展消息转换器...");

        // 1. 创建一个新的消息转换器对象
        MappingJackson2HttpMessageConverter messageConverter = new MappingJackson2HttpMessageConverter();

        // 2. 为它设置我们自定义的 ObjectMapper
        messageConverter.setObjectMapper(new CustomJacksonObjectMapper());

        // 3. 将这个转换器添加到列表的第0位，使其拥有最高优先级
        converters.add(0, messageConverter);
    }
}
```

> **提示：使用代码需谨慎。**

特点分析

- **完全控制**：对 JSON 的转换过程有最高级别的控制权。
- **逻辑清晰**：明确地创建并注册了转换器，行为非常直观。

注意事项

- 这种方式会覆盖 Spring Boot 的自动配置，导致 `application.yml` 中 `spring.jackson.*` 的配置项失效。
- 继承 `WebMvcConfigurationSupport` 会**完全接管 Spring MVC 的配置**，可能需要你**手动配置其他内容**（如静态资源映射等）。
- 如果只想扩展，实现 `WebMvcConfigurer` 接口通常是更好的选择。

### 对`application.yml`文件的解释

```yaml
mybatis:
  #mapper配置文件
  mapper-locations: classpath:mapper/*.xml #作用: 告诉 MyBatis 去哪里寻找 SQL 映射文件（Mapper XML 文件）。
 	详细解释
	你的 Java 代码中有 Mapper 接口（例如 EmployeeMapper.java），这些接口定义了要执行的数据库操作方法。
	但这些方法的具体 SQL 语句是写在 .xml 文件中的（例如 EmployeeMapper.xml）。
	mapper-locations 这个配置就是为了在 Java 接口和 XML 文件之间建立一座桥梁。MyBatis 启动时，会根据这个路径去加载所有的 SQL 语句。
	路径分解
	classpath:：这是一个协议前缀，代表从 "Java 类路径" 下开始查找。在标准的 Maven/Gradle 项目中，src/main/resources 目录下的所有内容都会被打包到类路径中。所以，classpath: 就等同于指向 resources 目录。
	mapper/：表示在 resources 目录下，有一个名为 mapper 的文件夹。
	*.xml：这是一个通配符，表示 mapper 文件夹下所有以 .xml 结尾的文件。
	简单来说，这个配置告诉 MyBatis：“请去 resources/mapper/ 文件夹下加载所有 XML 文件作为 SQL 映射文件。”
	
	
	
	
  type-aliases-package: com.sky.entity #作用: 为指定包下的所有 Java 类自动创建类型别名，让你在 XML 中可以直接使用类名，而无需写完整的包路径。
  没有这个配置时，你在 XML 文件中引用一个 Java 类（比如作为参数或返回值类型）时，必须写它的全限定类名：
  有了这个配置后，MyBatis 会自动扫描 com.sky.entity 包。当它发现 Employee.java 类时，就会为它注册一个别名 Employee（默认就是类名，不区分大小写）。然后你就可以在 XML 中直接写类名就行。
  简单来说，这个配置就是一个“偷懒”和“提升可读性”的利器，避免了在 XML 中反复写长长的包名。

  configuration:
    #开启驼峰命名
    map-underscore-to-camel-case: true #作用: 自动将数据库中下划线命名的列（snake_case）映射到 Java 对象中驼峰命名的属性（camelCase）。

	
```

### AOP与反射实现公共字段赋值

对于很多表结构都存在这样几个数据：

+ 创建时间，创建人id
+ 修改时间，修改人id

每次进行操作时，都要对这几个数据进行赋值操作，如果在每个方法中都添加赋值的代码，那就会造成代码冗余并且不可维护，如何自动实现这些功能呢？这就可以使用到面向切面编程。

如何实现？

```java
//1。定义枚举类型，参数是更新或者是插入
public enum OperationType {
    UPDATE,
    INSERT
}
//2.定义注解
@Target(ElementType.METHOD) 表示此注解是作用到方法上
@Retention(RetentionPolicy.RUNTIME) 
public @interface AutoFill {
    OperationType value();//注解中有一个value的属性，它的取值是枚举类型，也就是UPDATE或者INSERT中的一个
}
//3.定义切面类
//3.1
创建一个普通的java类，使用两个注解标记;
@Aspect
@Componet
//3.2在切面类中，使用 @Pointcut 注解定义一个或多个切点;
@Aspect
@Component
public class LoggingAspect {

    /**
     * 定义一个切点，匹配 com.example.service 包及其子包下的所有类的所有方法。
     * execution( [修饰符] 返回值类型 包名.类名.方法名(参数) [异常] )
     * .. 代表任意子包或任意参数
     * *  代表任意返回值、类名或方法名
     */
    @Pointcut("execution(* com.example.service.*.*(..))")
    public void serviceLayerPointcut() {
        // 这个方法体是空的，它只作为@Pointcut注解的载体，方便在通知中引用。
    }
    
}
//3.3创建通知(advice)
常用的通知类型包括：
@Before: 在目标方法执行之前执行。
@AfterReturning: 在目标方法成功返回后执行。可以获取方法的返回值。
@AfterThrowing: 在目标方法抛出异常后执行。可以获取异常信息。
@After: 在目标方法执行之后执行，无论方法是正常返回还是抛出异常（类似于 finally 块）。
@Around: 环绕通知。这是最强大的通知，它可以完全控制目标方法的执行。你可以决定是否执行目标方法、修改参数、修改返回值等。

    
@Aspect
@Component
@Slf4j
public class AutoFillAspect {
 
    //定义切点表达式
    @Pointcut("execution(* com.sky.mapper.*.*(..)) && @annotation(com.sky.annotation.AutoFill)")//返回值是任意，com.sky.mapper下的所有类中的所有方法，返回值是任意
    public void autoFillPointCut(){
    }

    @Before("autoFillPointCut()")
    public void autoFill(JoinPoint joinPoint){

        log.info("开始对公共字段进行填充");

        //获得到当前被拦截方法的数据库操作类型

        MethodSignature signature = (MethodSignature)joinPoint.getSignature();
        AutoFill autoFill = signature.getMethod().getAnnotation(AutoFill.class);
        OperationType operationType = autoFill.value();

        //获得到当前被拦截方法的参数--实体对象
        Object[] args = joinPoint.getArgs();
        if(args==null || args.length == 0) return;
        Object entity = args[0];
        //准备赋值的数据
        LocalDateTime now = LocalDateTime.now();
        Long currentId = BaseContext.getCurrentId();
        //根据当前不同的操作类型，为对应的属性通过反射来赋值

        if (operationType == OperationType.INSERT){
            try {
                Method createTime = entity.getClass().getDeclaredMethod("setCreateTime", LocalDateTime.class);
                Method updateTime = entity.getClass().getDeclaredMethod("setUpdateTime", LocalDateTime.class);
                Method createUser = entity.getClass().getDeclaredMethod("setCreateUser", Long.class);
                Method updateUser = entity.getClass().getDeclaredMethod("setUpdateUser", Long.class);

                //通过反射为对象属性赋值
                createTime.invoke(entity,now);
                createUser.invoke(entity,currentId);
                updateUser.invoke(entity,currentId);
                updateTime.invoke(entity,now);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }

        }else if(operationType == OperationType.UPDATE){
            try {
                Method updateTime = entity.getClass().getDeclaredMethod("setUpdateTime", LocalDateTime.class);
                Method updateUser = entity.getClass().getDeclaredMethod("setUpdateUser", Long.class);

                //通过反射为对象属性赋值
                updateUser.invoke(entity,currentId);
                updateTime.invoke(entity,now);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }
        log.info("公共字段填充结束");
    }
}

//可以在切点表达式上面加上&&@annotation(com.sky.annotation.AutoFill)注解表示还需要有AutoFill这个注解的标记才行
```

### 基于PageHelper分页插件实现分页查询步骤（从0开始）

#### 1controller

建立一个新的controller,加上@RestController和@Slf4j注解，如果这个controller所有的访问路径都是由公共的前缀的话，可以加上@RequestMaping注解抽取公共前缀，如果用到swagger的话可以加上@Api(tag = "描述这个接口信息")

分页查询返回和增删改查的并不相同，它的返回值是Result<PageResult>

```java
@Data
@AllArgsConstructor
@NoArgsConstructor
public class PageResult implements Serializable {

    private long total; //总记录数

    private List records; //当前页数据集合
}
```

接受数据，将传过来的数据封装为一个DTO如下：

```java
public class DishPageQueryDTO implements Serializable {

    private int page;

    private int pageSize;

    private String name;

    //分类id
    private Integer categoryId;

    //状态 0表示禁用 1表示启用
    private Integer status;
}
page和pageSize是必要的，剩下三个是条件查询参数，非必要，因此我们在查询时之就看是否传入这几个参数
```

#### 2service

完成上述工作后，就要调用service层的代码了，现在service包下建立一个接口，不需要加任何注解，

里面写上分页查询的方法（返回值写PageResult）就可以了，然后再service包下的imp包中创建实现类，实现类要加上@Service注解，并且重写接口中的所有方法，方法体里面写逻辑，暂时先不写。回到controller层，使用@Autowired注入Service层的接口，在分页查询方法中使用注入的Bean调用分页查询方法，返回值是自定义的PageResult类型，最后返回Result.success(pageResult);

->service->iml->开始写分页查询逻辑，这里就是用到了PageHelper插件.

```java
PageHelper.startPage(dishPageQueryDTO.getPage(),dishPageQueryDTO.getPageSize());

```

#### 3Mapper

完成上述工作后，会使用到Mapper接口对数据库进行查询操作，我们新建mapper接口，加上@Mapper注解，然后定义相应的xml文件

```xml
这都是固定套路
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd" >
<mapper namespace="这里写全类名如，com.sky.mapper.*mapper">

    
</mapper>
出现MyBatis的标签如果点击可以回到mapper中就表示映射成功。
```

接下来回到service层，我们使用@Autowired注入我们建立好的mapper,然后在startPage()后面调用mapper层的方法，然后返回值是固定的Page类型，并且需要指定泛型，这个类型就是mapper中需要返回的类型。拿到page后就可以得到总数量和前端传过来的页码数据，我们直接返回即可。

```java
return new PageResult(page.getTotal(),page.getResult());
```

## Day5

### Redis

#### 字符串操作命令

| 命令                      | 说明                                                |
| :------------------------ | :-------------------------------------------------- |
| `SET key value`           | 设置指定key的值                                     |
| `GET key`                 | 获取指定key的值                                     |
| `SETEX key seconds value` | 设置指定key的值，并将 key 的过期时间设为 seconds 秒 |
| `SETNX key value`         | 只有在 key 不存在时设置 key 的值                    |

#### 哈希操作命令

Redis hash 是一个 string 类型的 field 和 value 的映射表, hash 特别适合用于存储对象, 常用命令:

| 命令                   | 说明                                       |
| :--------------------- | :----------------------------------------- |
| `HSET key field value` | 将哈希表 key 中的字段 field 的值设为 value |
| `HGET key field`       | 获取存储在哈希表中指定字段的值             |
| `HDEL key field`       | 删除存储在哈希表中的指定字段               |
| `HKEYS key`            | 获取哈希表中所有字段                       |
| `HVALS key`            | 获取哈希表中所有值                         |

#### 列表操作命令

Redis 列表是简单的字符串列表，按照插入顺序排序，常用命令：

| 命令                        | 说明                         |
| :-------------------------- | :--------------------------- |
| `LPUSH key value1 [value2]` | 将一个或多个值插入到列表头部 |
| `LRANGE key start stop`     | 获取列表指定范围内的元素     |
| `RPOP key`                  | 移除并获取列表最后一个元素   |
| `LLEN key`                  | 获取列表长度                 |

#### 集合操作命令

Redis set 是string类型的无序集合。集合成员是唯一的，集合中不能出现重复的数据，常用命令：

| 命令                         | 说明                     |
| :--------------------------- | :----------------------- |
| `sadd key member1 [member2]` | 向集合添加一个或多个成员 |
| `smembers key`               | 返回集合中的所有成员     |
| `scard key`                  | 获取集合的成员数         |
| `sinter key1 [key2]`         | 返回给定所有集合的交集   |
| `sunion key1 [key2]`         | 返回所有给定集合的并集   |
| `srem key member1 [member2]` | 删除集合中一个或多个成员 |

#### 有序集合操作命令

Redis 有序集合是string类型元素的集合，且不允许有重复成员。每个元素都会关联一个double类型的分数。常用命令：

| 命令                                       | 说明                                         |
| :----------------------------------------- | :------------------------------------------- |
| `ZADD key score1 member1 [score2 member2]` | 向有序集合添加一个或多个成员                 |
| `ZRANGE key start stop [WITHSCORES]`       | 通过索引区间返回有序集合中指定区间内的成员   |
| `ZINCRBY key increment member`             | 有序集合中对指定成员的分数加上增量 increment |
| `ZREM key member [member ...]`             | 移除有序集合中的一个或多个成员               |

#### 通用命令

Redis的通用命令是不分数据类型的, 都可以使用的命令:

| 命令           | 说明                                 |
| :------------- | :----------------------------------- |
| `keys pattern` | 查找所有符合给定模式( pattern)的 key |
| `exists key`   | 检查给定 key 是否存在                |
| `type key`     | 返回 key 所储存的值的类型            |
| `del key`      | 该命令用于在 key 存在是删除 key      |

### 如何在java中操纵Redis?

1.导入Spring Data Redis的maven坐标

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

2.配置Redis数据源

在`application.yml`文件中配置

```yml
spring:
	redis:
		host: localhost
		port: 6379
		database: 0-15
		password: 无密码
```

3.编写配置类，创建RedisTemplate对象

```java
@Configuration
@Slf4j
public class RedisConfiguration {

    @Bean
    public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory){
        log.info("开始创建redis模板对象");
        RedisTemplate redisTemplate = new RedisTemplate();
        redisTemplate.setConnectionFactory(redisConnectionFactory);
        redisTemplate.setKeySerializer(new StringRedisSerializer());
        return redisTemplate;
    }
}
```

4.通过RedisTemplate对象操作redis

```java
//通过@AutoWired注解注入RedisTemplate对象
@Autowired
RedisTemplate redisTemplate;
ValueOperations valueOperations = redisTemplate.opsForValue();//获得操作字符串的对象
HashOperations hashOperations = redisTemplate.opsForHash();
ListOperations listOperations = redisTemplate.opsForList();
SetOperations setOperations = redisTemplate.opsForSet();
ZSetOperations zSetOperations = redisTemplate.opsForZSet();
```

实例：

```java
 @Test
    void testStringOperations() {
        System.out.println("------ 开始测试 String 操作 ------");

        // 1. 获取操作 String 的 Operations 对象
        ValueOperations<String, Object> opsForValue = redisTemplate.opsForValue();

        // 2. SET key value: 设置指定key的值
        System.out.println("执行 SET mykey myvalue");
        opsForValue.set("mykey", "myvalue");

        // 3. GET key: 获取指定key的值
        String value = (String) opsForValue.get("mykey");
        System.out.println("执行 GET mykey, 结果: " + value);

        // 4. SETEX key seconds value: 设置带过期时间的key-value
        System.out.println("执行 SETEX mykey_with_ttl 10 temporary_value");
        opsForValue.set("mykey_with_ttl", "temporary_value", 10, TimeUnit.SECONDS);
        System.out.println("等待2秒后获取 mykey_with_ttl 的过期时间: " + redisTemplate.getExpire("mykey_with_ttl", TimeUnit.SECONDS) + "秒");


        // 5. SETNX key value: 只有在 key 不存在时设置 key 的值
        System.out.println("尝试 SETNX mykey new_value (key已存在)");
        Boolean success1 = opsForValue.setIfAbsent("mykey", "new_value");
        System.out.println("操作结果: " + success1 + ", mykey 当前值: " + opsForValue.get("mykey"));

        System.out.println("尝试 SETNX newkey my_new_value (key不存在)");
        Boolean success2 = opsForValue.setIfAbsent("newkey", "my_new_value");
        System.out.println("操作结果: " + success2 + ", newkey 当前值: " + opsForValue.get("newkey"));

        System.out.println("------ String 操作测试结束 ------\n");
    }

    /**
     * =================================================================
     * 二、哈希 (Hash) 操作
     * 对应笔记中的：HSET, HGET, HDEL, HKEYS, HVALS
     * =================================================================
     */
    @Test
    void testHashOperations() {
        System.out.println("------ 开始测试 Hash 操作 ------");

        // 1. 获取操作 Hash 的 Operations 对象
        HashOperations<String, Object, Object> opsForHash = redisTemplate.opsForHash();
        String hashKey = "user:1001";

        // 2. HSET key field value: 设置哈希字段
        System.out.println("执行 HSET " + hashKey + " name 'John Doe'");
        opsForHash.put(hashKey, "name", "John Doe");
        
        System.out.println("执行 HSET " + hashKey + " age 30");
        opsForHash.put(hashKey, "age", "30"); // 存储时通常都存为字符串

        // 也可以一次性设置多个字段
        Map<String, String> userFields = new HashMap<>();
        userFields.put("email", "john.doe@example.com");
        userFields.put("city", "New York");
        System.out.println("执行 HMSET " + hashKey + " email ... city ...");
        opsForHash.putAll(hashKey, userFields);


        // 3. HGET key field: 获取哈希字段值
        String name = (String) opsForHash.get(hashKey, "name");
        System.out.println("执行 HGET " + hashKey + " name, 结果: " + name);

        // 4. HKEYS key: 获取所有字段
        Set<Object> fields = opsForHash.keys(hashKey);
        System.out.println("执行 HKEYS " + hashKey + ", 结果: " + fields);

        // 5. HVALS key: 获取所有值
        List<Object> values = opsForHash.values(hashKey);
        System.out.println("执行 HVALS " + hashKey + ", 结果: " + values);

        // 6. HDEL key field: 删除哈希字段
        System.out.println("执行 HDEL " + hashKey + " city");
        opsForHash.delete(hashKey, "city");
        System.out.println("删除后，再次执行 HKEYS " + hashKey + ", 结果: " + opsForHash.keys(hashKey));

        System.out.println("------ Hash 操作测试结束 ------\n");
    }

    /**
     * =================================================================
     * 三、列表 (List) 操作
     * 对应笔记中的：LPUSH, LRANGE, RPOP, LLEN
     * =================================================================
     */
    @Test
    void testListOperations() {
        System.out.println("------ 开始测试 List 操作 ------");

        // 1. 获取操作 List 的 Operations 对象
        ListOperations<String, Object> opsForList = redisTemplate.opsForList();
        String listKey = "tasks";

        // 2. LPUSH key value1 [value2...]: 从左侧（头部）推入元素
        System.out.println("执行 LPUSH " + listKey + " task3 task2 task1");
        opsForList.leftPushAll(listKey, "task3", "task2", "task1"); // 顺序插入后，列表为 [task1, task2, task3]
        
        // 3. LLEN key: 获取列表长度
        Long size = opsForList.size(listKey);
        System.out.println("执行 LLEN " + listKey + ", 结果: " + size);

        // 4. LRANGE key start stop: 获取指定范围的元素
        // (0, -1) 表示获取所有元素
        List<Object> allTasks = opsForList.range(listKey, 0, -1);
        System.out.println("执行 LRANGE " + listKey + " 0 -1, 结果: " + allTasks);

        // 5. RPOP key: 从右侧（尾部）弹出一个元素
        Object lastTask = opsForList.rightPop(listKey);
        System.out.println("执行 RPOP " + listKey + ", 弹出的元素是: " + lastTask); // 弹出 task3
        System.out.println("RPOP 后，列表内容: " + opsForList.range(listKey, 0, -1));

        System.out.println("------ List 操作测试结束 ------\n");
    }

    /**
     * =================================================================
     * 四、集合 (Set) 操作
     * 对应笔记中的：SADD, SMEMBERS, SCARD, SINTER, SUNION, SREM
     * =================================================================
     */
    @Test
    void testSetOperations() {
        System.out.println("------ 开始测试 Set 操作 ------");

        // 1. 获取操作 Set 的 Operations 对象
        SetOperations<String, Object> opsForSet = redisTemplate.opsForSet();
        String setKey1 = "employees:dept1";
        String setKey2 = "employees:dept2";

        // 2. SADD key member1 [member2...]: 添加成员
        System.out.println("执行 SADD " + setKey1 + " Alice Bob Charlie");
        opsForSet.add(setKey1, "Alice", "Bob", "Charlie");
        System.out.println("执行 SADD " + setKey2 + " Charlie David Eve");
        opsForSet.add(setKey2, "Charlie", "David", "Eve");

        // 3. SMEMBERS key: 查看所有成员
        Set<Object> members1 = opsForSet.members(setKey1);
        System.out.println("执行 SMEMBERS " + setKey1 + ", 结果: " + members1);

        // 4. SCARD key: 获取集合成员数
        Long size1 = opsForSet.size(setKey1);
        System.out.println("执行 SCARD " + setKey1 + ", 结果: " + size1);

        // 5. SINTER key1 key2: 获取交集
        Set<Object> intersection = opsForSet.intersect(setKey1, setKey2);
        System.out.println("执行 SINTER " + setKey1 + " " + setKey2 + ", 结果: " + intersection);

        // 6. SUNION key1 key2: 获取并集
        Set<Object> union = opsForSet.union(setKey1, setKey2);
        System.out.println("执行 SUNION " + setKey1 + " " + setKey2 + ", 结果: " + union);

        // 7. SREM key member: 移除成员
        System.out.println("执行 SREM " + setKey1 + " Bob");
        opsForSet.remove(setKey1, "Bob");
        System.out.println("移除 Bob 后, " + setKey1 + " 的成员: " + opsForSet.members(setKey1));

        System.out.println("------ Set 操作测试结束 ------\n");
    }


    /**
     * =================================================================
     * 五、有序集合 (ZSet) 操作
     * 对应笔记中的：ZADD, ZRANGE, ZINCRBY, ZREM
     * =================================================================
     */
    @Test
    void testZSetOperations() {
        System.out.println("------ 开始测试 ZSet 操作 ------");

        // 1. 获取操作 ZSet 的 Operations 对象
        ZSetOperations<String, Object> opsForZSet = redisTemplate.opsForZSet();
        String zsetKey = "leaderboard";

        // 2. ZADD key score member: 添加成员和分数
        System.out.println("执行 ZADD " + zsetKey + " 100 PlayerOne 95 PlayerTwo 80 PlayerThree");
        opsForZSet.add(zsetKey, "PlayerOne", 100);
        opsForZSet.add(zsetKey, "PlayerTwo", 95);
        opsForZSet.add(zsetKey, "PlayerThree", 80);

        // 3. ZRANGE key start stop: 按分数排序后，通过索引区间返回成员
        // (0, -1) 表示获取所有成员，按分值从小到大排序
        Set<Object> players = opsForZSet.range(zsetKey, 0, -1);
        System.out.println("执行 ZRANGE " + zsetKey + " 0 -1 (按分值升序), 结果: " + players);

        // 4. ZRANGE key start stop WITHSCORES: 返回成员及分数
        Set<ZSetOperations.TypedTuple<Object>> playersWithScores = opsForZSet.rangeWithScores(zsetKey, 0, -1);
        System.out.println("执行 ZRANGE ... WITHSCORES, 结果:");
        for (ZSetOperations.TypedTuple<Object> player : playersWithScores) {
            System.out.println("  成员: " + player.getValue() + ", 分数: " + player.getScore());
        }
        
        // 5. ZINCRBY key increment member: 增加成员的分数
        Double newScore = opsForZSet.incrementScore(zsetKey, "PlayerThree", 10);
        System.out.println("执行 ZINCRBY " + zsetKey + " 10 PlayerThree, PlayerThree的新分数: " + newScore);

        // 6. ZREM key member: 移除成员
        opsForZSet.remove(zsetKey, "PlayerTwo");
        System.out.println("执行 ZREM " + zsetKey + " PlayerTwo, 移除后排行榜: " + opsForZSet.range(zsetKey, 0, -1));

        System.out.println("------ ZSet 操作测试结束 ------\n");
    }

    /**
     * =================================================================
     * 六、通用命令
     * 对应笔记中的：KEYS, EXISTS, TYPE, DEL
     * =================================================================
     */
    @Test
    void testGenericOperations() {
        System.out.println("------ 开始测试通用命令 ------");

        // 准备一些数据
        redisTemplate.opsForValue().set("stringKey", "hello");
        redisTemplate.opsForList().leftPush("listKey", "a");
        redisTemplate.opsForHash().put("hashKey", "field", "value");

        // 1. KEYS pattern: 查找所有符合模式的 key
        // ！！！注意：KEYS 命令在生产环境要慎用，可能导致性能问题。
        // 在数据量大时，应使用 SCAN 命令代替。
        Set<String> keys = redisTemplate.keys("*Key");
        System.out.println("执行 KEYS *Key, 结果: " + keys);

        // 2. EXISTS key: 检查 key 是否存在
        Boolean exists = redisTemplate.hasKey("stringKey");
        System.out.println("执行 EXISTS stringKey, 结果: " + exists);
        Boolean notExists = redisTemplate.hasKey("nonexistentKey");
        System.out.println("执行 EXISTS nonexistentKey, 结果: " + notExists);

        // 3. TYPE key: 返回 key 的数据类型
        DataType type = redisTemplate.type("listKey");
        System.out.println("执行 TYPE listKey, 结果: " + type.name()); // 返回 STRING, HASH, LIST, SET, ZSET

        // 4. DEL key: 删除 key
        System.out.println("执行 DEL stringKey, hashKey");
        redisTemplate.delete("stringKey"); // 删除单个 key
        // redisTemplate.delete(keys); // 也可以删除多个 key
        System.out.println("删除后，再次检查 stringKey 是否存在: " + redisTemplate.hasKey("stringKey"));
        
        System.out.println("------ 通用命令测试结束 ------\n");
    }
}
```

## Day6

### HttpClient

#### 1 通过HttpClient发送一个Get方式的请求

```java
public void testGET() throws Exception{
    //创建httpclient对象
    CloseableHttpClient httpClient = HttpClients.createDefault();

    //创建请求对象
    HttpGet httpGet = new HttpGet("http://localhost:8080/user/shop/status");

    //发送请求，接受响应结果
    CloseableHttpResponse response = httpClient.execute(httpGet);
    //获取服务端返回的状态码
    int statusCode = response.getStatusLine().getStatusCode();
    System.out.println("服务端返回的状态码为：" + statusCode);
    HttpEntity entity = response.getEntity();
    String body = EntityUtils.toString(entity);
    System.out.println("服务端返回的数据为：" + body);
    //关闭资源
    response.close();
    httpClient.close();
}
```

#### 2 通过HttpClient发送一个Post方式的请求

```java
public void testPOST() throws Exception{
    // 创建httpclient对象
    CloseableHttpClient httpClient = HttpClients.createDefault();

    //创建请求对象
    HttpPost httpPost = new HttpPost("http://localhost:8080/admin/employee/login");

    JSONObject jsonObject = new JSONObject();
    jsonObject.put("username","admin");
    jsonObject.put("password","123456");

    StringEntity entity = new StringEntity(jsonObject.toString());
    //指定请求编码方式
    entity.setContentEncoding("utf-8");
    //数据格式
    entity.setContentType("application/json");
    httpPost.setEntity(entity);

    //发送请求
    CloseableHttpResponse response = httpClient.execute(httpPost);

    //解析返回结果
    int statusCode = response.getStatusLine().getStatusCode();
    System.out.println("响应码为：" + statusCode);

    HttpEntity entity1 = response.getEntity();
    String body = EntityUtils.toString(entity1);
    System.out.println("响应数据为：" + body);

    //关闭资源
    response.close();
    httpClient.close();
}
```

#### 工具类

由于结构很固定，因此黑马将其封装了一个工具类，这太好了，说不定工作的时候可以用到。

```java
package com.sky.utils;

import com.alibaba.fastjson.JSONObject;
import org.apache.http.NameValuePair;
import org.apache.http.client.config.RequestConfig;
import org.apache.http.client.entity.UrlEncodedFormEntity;
import org.apache.http.client.methods.CloseableHttpResponse;
import org.apache.http.client.methods.HttpGet;
import org.apache.http.client.methods.HttpPost;
import org.apache.http.client.utils.URIBuilder;
import org.apache.http.entity.StringEntity;
import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.impl.client.HttpClients;
import org.apache.http.message.BasicNameValuePair;
import org.apache.http.util.EntityUtils;

import java.io.IOException;
import java.net.URI;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;

/**
 * Http工具类
 */
public class HttpClientUtil {

    static final  int TIMEOUT_MSEC = 5 * 1000;

    /**
     * 发送GET方式请求
     * @param url
     * @param paramMap
     * @return
     */
    public static String doGet(String url,Map<String,String> paramMap){
        // 创建Httpclient对象
        CloseableHttpClient httpClient = HttpClients.createDefault();

        String result = "";
        CloseableHttpResponse response = null;

        try{
            URIBuilder builder = new URIBuilder(url);
            if(paramMap != null){
                for (String key : paramMap.keySet()) {
                    builder.addParameter(key,paramMap.get(key));
                }
            }
            URI uri = builder.build();

            //创建GET请求
            HttpGet httpGet = new HttpGet(uri);

            //发送请求
            response = httpClient.execute(httpGet);

            //判断响应状态
            if(response.getStatusLine().getStatusCode() == 200){
                result = EntityUtils.toString(response.getEntity(),"UTF-8");
            }
        }catch (Exception e){
            e.printStackTrace();
        }finally {
            try {
                response.close();
                httpClient.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

        return result;
    }

    /**
     * 发送POST方式请求
     * @param url
     * @param paramMap
     * @return
     * @throws IOException
     */
    public static String doPost(String url, Map<String, String> paramMap) throws IOException {
        // 创建Httpclient对象
        CloseableHttpClient httpClient = HttpClients.createDefault();
        CloseableHttpResponse response = null;
        String resultString = "";

        try {
            // 创建Http Post请求
            HttpPost httpPost = new HttpPost(url);

            // 创建参数列表
            if (paramMap != null) {
                List<NameValuePair> paramList = new ArrayList();
                for (Map.Entry<String, String> param : paramMap.entrySet()) {
                    paramList.add(new BasicNameValuePair(param.getKey(), param.getValue()));
                }
                // 模拟表单
                UrlEncodedFormEntity entity = new UrlEncodedFormEntity(paramList);
                httpPost.setEntity(entity);
            }

            httpPost.setConfig(builderRequestConfig());

            // 执行http请求
            response = httpClient.execute(httpPost);

            resultString = EntityUtils.toString(response.getEntity(), "UTF-8");
        } catch (Exception e) {
            throw e;
        } finally {
            try {
                response.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

        return resultString;
    }

    /**
     * 发送POST方式请求
     * @param url
     * @param paramMap
     * @return
     * @throws IOException
     */
    public static String doPost4Json(String url, Map<String, String> paramMap) throws IOException {
        // 创建Httpclient对象
        CloseableHttpClient httpClient = HttpClients.createDefault();
        CloseableHttpResponse response = null;
        String resultString = "";

        try {
            // 创建Http Post请求
            HttpPost httpPost = new HttpPost(url);

            if (paramMap != null) {
                //构造json格式数据
                JSONObject jsonObject = new JSONObject();
                for (Map.Entry<String, String> param : paramMap.entrySet()) {
                    jsonObject.put(param.getKey(),param.getValue());
                }
                StringEntity entity = new StringEntity(jsonObject.toString(),"utf-8");
                //设置请求编码
                entity.setContentEncoding("utf-8");
                //设置数据类型
                entity.setContentType("application/json");
                httpPost.setEntity(entity);
            }

            httpPost.setConfig(builderRequestConfig());

            // 执行http请求
            response = httpClient.execute(httpPost);

            resultString = EntityUtils.toString(response.getEntity(), "UTF-8");
        } catch (Exception e) {
            throw e;
        } finally {
            try {
                response.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

        return resultString;
    }
    private static RequestConfig builderRequestConfig() {
        return RequestConfig.custom()
                .setConnectTimeout(TIMEOUT_MSEC)
                .setConnectionRequestTimeout(TIMEOUT_MSEC)
                .setSocketTimeout(TIMEOUT_MSEC).build();
    }

}
```

## Day7

### SpringCache

#### 常用注解：

| 注解               | 说明                                                         |
| :----------------- | :----------------------------------------------------------- |
| **@EnableCaching** | 开启缓存注解功能，通常加在启动类上                           |
| **@Cacheable**     | 在方法执行前先查询缓存中是否有数据，如果有数据，则直接返回缓存数据；如果没有缓存数据，调用方法并将方法返回值放到缓存中 |
| **@CachePut**      | 将方法的返回值放到缓存中                                     |
| **@CacheEvict**    | 将一条或多条数据从缓存中删除                                 |

#### 背景：

​		对于一个接口来说，如果我们每次访问都从数据库中进行查找，那么如果很多人都访问这样的接口，就会导致数据库性能降低，给用户带来不好的体验，因此我们可以将从这些接口查出来的数据放到redis中，这样就可以很快的查出来，但是如果说这些接口的数据有了变化，我们就需要手动的去清除redis中的缓存数据，这是一个重复且无意义的过程，因此spring-cache诞生，通过一些简单的注解就可以替我们实现这些重复的代码。

#### 如何使用？

首先要引入spring-cache的依赖

```xml
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-cache</artifactId>
        </dependency>
```

其次在启动类上加上`@EnableCaching`目的是开启缓存注解功能

在需要的类上加上注解就行了。

## Day10

### spring task

定位：定时任务框架

作用：定时自动执行某段java代码

#### cron表达式

本质是字符串，用来表示什么时间进行提醒，直接去网站上搜索需要的，不需要自己写，了解作用即可。

#### Spring Task 使用步骤：

① 导入 maven 坐标 spring - context（已存在）非常小的东西，在spring-boot-starter中就有
② 启动类添加注解 @EnableScheduling 开启任务调度(和开启事务缓存那个差不多)
③ 自定义定时任务类

对于第三点，我们新建一个task包，自定义类，在类上加上@Componet注解，在方法上加上@Scheduled(cron = "表达式")

### WebSocket

#### 如何使用？

1. pom中添加依赖

   ```java
   <dependency>
       <groupId>org.springframework.boot</groupId>
       <artifactId>spring-boot-starter-websocket</artifactId>
   </dependency>
   ```

2. 开启 WebSocket 支持

   创建一个配置类，用于声明和启用 WebSocket。

   ```java
   /**
    * WebSocket 配置类
    *
    * @author YourName
    */
   @Configuration
   public class WebSocketConfig {
   
       /**
        * 注入 ServerEndpointExporter Bean。
        * 这个 Bean会自动注册所有带有 @ServerEndpoint 注解的类。
        * 当使用外部嵌入式的Servlet容器（如Tomcat）时，需要手动注入这个Bean。
        * 如果是部署到独立的Servlet容器中，则不需要此配置。
        * @return ServerEndpointExporter
        */
       @Bean
       public ServerEndpointExporter serverEndpointExporter() {
           return new ServerEndpointExporter();
       }
   }
   ```

3. 编写websocket服务类

   ```java
    /**
    * WebSocket服务
    */
   @Component
   @ServerEndpoint("/ws/{sid}")
   public class WebSocketServer {
   
       //存放会话对象
       private static Map<String, Session> sessionMap = new HashMap();
   
       /**
        * 连接建立成功调用的方法
        */
       @OnOpen
       public void onOpen(Session session, @PathParam("sid") String sid) {
           System.out.println("客户端：" + sid + "建立连接");
           sessionMap.put(sid, session);
       }
   
       /**
        * 收到客户端消息后调用的方法
        *
        * @param message 客户端发送过来的消息
        */
       @OnMessage
       public void onMessage(String message, @PathParam("sid") String sid) {
           System.out.println("收到来自客户端：" + sid + "的信息:" + message);
       }
   
       /**
        * 连接关闭调用的方法
        *
        * @param sid
        */
       @OnClose
       public void onClose(@PathParam("sid") String sid) {
           System.out.println("连接断开:" + sid);
           sessionMap.remove(sid);
       }
   
       /**
        * 群发
        *
        * @param message
        */
       public void sendToAllClient(String message) {
           Collection<Session> sessions = sessionMap.values();
           for (Session session : sessions) {
               try {
                   //服务器向客户端发送消息
                   session.getBasicRemote().sendText(message);
               } catch (Exception e) {
                   e.printStackTrace();
               }
           }
       }
   
   }
   ```

有点类似于Controller，被动接受信息，也可以主动去发送，不过发送要注入
